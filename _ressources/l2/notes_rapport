# ____________________cache locality
Ref: https://stackoverflow.com/questions/19328909/nested-loop-optimisation-in-c-and-openmp
checking something like

int a[10000][10000];
for(int i = 0; i < 10000; i++){
    for(int j = 0; j < 10000; j++){
       a[i][j]++;               <-- good cache locality
       a[j][i]++;               <-- bad cache locality
    }
}

"In computer science, locality of reference, also known as the principle of locality,[1] is the tendency of a processor to access the same set of memory locations repetitively over a short period of time.[2] There are two basic types of reference locality – temporal and spatial locality. Temporal locality refers to the reuse of specific data, and/or resources, within a relatively small time duration. Spatial locality (also termed data locality[3]) refers to the use of data elements within relatively close storage locations. Sequential locality, a special case of spatial locality, occurs when data elements are arranged and accessed linearly, such as, traversing the elements in a one-dimensional array."

_____ CRITICAL vs ATOMIC
- CRITICAL can encapsulate a block where only one thread can enter at once, turning it into a sequential code inside a paralleized loop
- ATOMIC provides mutual exclusion but only to a specific memory location. It is generally faster than critical and applied to a single assignment that follows it

_____ GENERAL RULES
# DO NOT use omp for loops inside a FOR loop. Overheads have ^2 incurrance
1) use omp for inside a another parallel for
        #pragma omp parallel for
        for (int i = 0; i < 3; ++i) {
            #pragma omp for
            for (int j = 0; j < 6; ++j) {
                c(i, j);
            }
        }
2) parallel for twice outside and inside
        #pragma omp parallel for
        for (int i = 0; i < 3; ++i) {
            #pragma omp parallel for
            for (int j = 0; j < 6; ++j) {
                c(i, j);
            }
        }
3) use parallel for inside inner loop. REASON : In each iteration of outerloop, a parallel region is created causing overhead.
        for (int i = 0; i < 3; ++i) {
            #pragma omp parallel for
            for (int j = 0; j < 6; ++j) {
                c(i, j);
            }
        }
    
    sources : http://ppc.cs.aalto.fi/ch3/nested/

____ COLLAPSE 
- https://stackoverflow.com/questions/15160570/openmp-with-collapse-for-nested-for-loops-performs-worse-when-without
- can be used when we have perfectly nested loops

_____ ENCAPSULATE USING #pragma omp parallel
- http://ppc.cs.aalto.fi/ch3/for/

_____ PRIVATE/SHARED
- http://jakascorner.com/blog/2016/06/omp-data-sharing-attributes.html
- https://www3.nd.edu/~zxu2/acms60212-40212-S12/Lec-11-01.pdf (slides with point form)
- if int is declared outside of #pragma omp parallel without specification, it is shared by default when parallelized. If internally declared, it is private.
–private (variable list)•Specifies variables local to each thread
–firstprivate(variable list)•Similar to the private•Private variables are initialized to variable value before the parallel directive
–shared (variable list)•Specifies variables that are shared among all the threads
–default (data scoping specifier)•Default data scoping specifiermay be shared or none

_____ SCHEDULING
: http://ppc.cs.aalto.fi/ch3/schedule/


_____ OBSERVATIONS
- on a 2x for perfect loops, collapse(2) is faster than schedule(static) because both loops are parallelized

_____ other good slides
- https://people.math.umass.edu/~johnston/PHI_WG_2014/OpenMPSlides_tamu_sc.pdf (good for dummies and definitions). AMDAHLS LAW
-https://www3.nd.edu/~zxu2/acms60212-40212-S12/Lec-11-01.pdf lots of examples and explanations
- quebec reference?? https://wiki.calculquebec.ca/w/Parall%C3%A9lisation?setlang=en
- openmp loop optimizations : http://akira.ruc.dk/~keld/teaching/IPDC_f10/Slides/pdf4x/4_Performance.4x.pdf

______ stackoverflow reference
- parallelizing 4 loops : https://stackoverflow.com/questions/48037155/how-can-i-best-parallelise-a-set-of-four-nested-for-loops-in-a-brute-force-a

=========FINAL NOTES FOR PROB 1

original code

    for (int k = 1; k <= iterations; k++)
        for (int j = 0; j < cols; j++)
            for (int i = 0; i < rows; i++)
                matrix[i][j] = matrix[i][j] + i + j;

1) first, we swapped i and j loops so that j would be internal for better cache locality (this is called Exchange in our class notes)
2) then, because k is a dependency on an external loop, we do another exchange to internalize it
3) we see an opportunity to eliminate k loop and integrate it into a single line, reducing our problem to 2 loops for better parallization
4) use collapse to paral the 2 for loops. each para instance only needs 1 instance of instruction. no race conditions.

=========FINAL NOTES FOR PROB 2

original code

    for (int k = 1; k <= iterations; k++)
		for (int i = 0; i < rows; i++)
			for (int j = cols - 1; j >= 0; j--)
				if (j == cols - 1)
				{
					matrix[i][j] = matrix[i][j] + i;
				} else
				{
					matrix[i][j] = matrix[i][j] + matrix[i][j+1];
				}
			}
		}
	}

FINAL design
1) Modify j loop so iteration moves forward for better locality
2) Shift column initialization outside of j loop to remove if statement
3) swap i and k loops so we won't have to access i more than necessary per iteration. better  locality
4) we use dynamic scheduling since each i loop may not necessarily have the same iteration loops for improved load balancing.









----------------------------------------------------    reference
1) Since the last column of J is only initialized through i iterations, even though it doesn't need to be in the J loop, we should try to keep our perfect loop structure.
2) Invert J loop direction to positive
3) apply loop skew (torsion) between i and j
2) matrix[i][lastColumnJ] += i; DF matrix[i][j] += matrix[i][j + 1];


second design

1) start with k,i,j
2) apply torsion between i, j
3) apply torsion between k, j

it becomes

        for (int j = 1; j < maxJ + iterations - 1; j++)
        {
            for (int k = max(0, j - maxJ + 1); k <= min(j, iterations - 1); k++)
            {
                for (int i = max(0, j - k - cols + 1); i <= min(j - k, rows - 1); i++)
                {

-- canonical loop restrictions makes it hard to apply torsion and openmp 
https://www.openmp.org/spec-html/5.0/openmpsu40.html
https://stackoverflow.com/questions/7901681/openmp-cant-parallelize-nested-for-loops
-- different levels of parallelization
https://stackoverflow.com/questions/53207497/how-to-parallelize-for-loop-inside-other-for-loop-with-openmp
-- detecting nested parallisim!!
https://stackoverflow.com/questions/31520326/openmp-check-if-nested-parallesim

active-levels-var - the number of nested active parallel regions that enclose the current task such that all of the parallel regions are enclosed by the outermost initial task region on the current device. There is one copy of this ICV per data environment.